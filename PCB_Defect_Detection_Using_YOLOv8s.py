# -*- coding: utf-8 -*-
"""YOLOv8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12h9LRSlWF1ZF8lTaBwbvaAujBzUxJeeA

This code was adapted from multiple sources to develop an implementation for PCB defect detection using YOLOv8s. Specifically derived from:

https://github.com/Sammy970/PCB-Defect-detection-using-YOLOv8?source=post_page-----3460f922ce86---------------------------------------

The Kaggle notebook by Tatiana Kushniruk at https://www.kaggle.com/code/tatianakushniruk/pcb-defect-detection-with-yolov8/notebook#K-Fold-Cross-Validation

https://github.com/MBDNotes/YOLOv5_PCB_Defects_Detection


(Provided under the Apache License 2.0)
"""



"""**Section 1: Registering Dataset**"""

from google.colab import drive
drive.mount('/content/drive')

root_dir = '/content/drive/MyDrive/PCB_defect_detection'

!pip install ultralytics

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import cv2
import ultralytics
import os
import shutil
import random
import xml.etree.ElementTree as ET
import yaml
from pathlib import Path
from collections import Counter
from ultralytics import YOLO
from sklearn.model_selection import KFold

# Define the directory containing the dataset
dataset_dir = os.path.join(root_dir, 'PCB_DATASET')

# Print out the full directory structure of the dataset for verification
for root, dirs, files in os.walk(dataset_dir):
    for name in dirs:
        print(os.path.join(root, name))

# This function counts the number of files in a given folder.
def count_files_in_folder(folder_path):
    files = os.listdir(folder_path)
    return len(files)

# Define the subfolders representing different defect types
subfolders = ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']

images_dir = os.path.join(dataset_dir, 'images')
annot_dir = os.path.join(dataset_dir, 'Annotations')

# Print the number of images and annotation files for each defect type
for subfolder in subfolders:
    images_path = os.path.join(images_dir, subfolder)
    annot_path = os.path.join(annot_dir, subfolder)
    print(f'{subfolder:<15} \t{count_files_in_folder(images_path)} images \t{count_files_in_folder(annot_path)} annotations')

def parse_xml(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    data = []

    # Extract basic image information
    filename = root.find('filename').text
    width = int(root.find('size/width').text)
    height = int(root.find('size/height').text)

    # Extract bounding box information for each defect in the image
    for obj in root.findall('object'):
        name = obj.find('name').text
        xmin = int(obj.find('bndbox/xmin').text)
        ymin = int(obj.find('bndbox/ymin').text)
        xmax = int(obj.find('bndbox/xmax').text)
        ymax = int(obj.find('bndbox/ymax').text)
        data.append({
            'filename': filename,
            'width': width,
            'height': height,
            'class': name,
            'xmin': xmin,
            'ymin': ymin,
            'xmax': xmax,
            'ymax': ymax
        })
    return data

# Aggregate all parsed annotation data into a list and then create a DataFrame
all_data = []
for root, dirs, files in os.walk(annot_dir):
    for name in files:
        if name.endswith('.xml'):
            xml_path = os.path.join(root, name)
            all_data.extend(parse_xml(xml_path))

annot_df = pd.DataFrame(all_data)
print("Sample of parsed annotations:")
print(annot_df.head())

"""Visualisation"""

# Returns the appropriate defect subfolder based on the image filename.
def get_subfolder(image_name):
    if 'missing' in image_name.split('_'):
        return 'Missing_hole'
    if 'mouse' in image_name.split('_'):
        return 'Mouse_bite'
    if 'open' in image_name.split('_'):
        return 'Open_circuit'
    if 'short' in image_name.split('_'):
        return 'Short'
    if 'spur' in image_name.split('_'):
        return 'Spur'
    if 'spurious' in image_name.split('_'):
        return 'Spurious_copper'

# Loads an image, overlays bounding boxes from its corresponding annotation,
# and displays the image.
def visualize_annotations(image_name, images_dir, annot_df, is_subfolder=False):
    # Construct the correct image path based on subfolder organization
    if is_subfolder:
        image_path = os.path.join(images_dir, get_subfolder(image_name), image_name)
    else:
        image_path = os.path.join(images_dir, image_name)

    # Load image using OpenCV
    image = cv2.imread(image_path)

    # Filter annotations specific to the provided image
    annotations = annot_df[annot_df['filename'] == image_name]

    # Draw each bounding box and its class label on the image
    for _, annot in annotations.iterrows():
        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']
        class_label = annot['class']
        # If confidence exists, append to label (if available in your dataset)
        confidence = annot.get('confidence')
        if confidence is not None:
            class_label += f" ({confidence:.2f})"
        color = (255, 255, 255)
        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 3)
        # Add background rectangle behind text for visibility
        text_size = cv2.getTextSize(class_label, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 2)[0]
        cv2.rectangle(image, (xmin, ymin - text_size[1] - 5), (xmin + text_size[0], ymin - 1), color, -1)
        cv2.putText(image, class_label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)

    # Convert from BGR (OpenCV default) to RGB for correct display via Matplotlib
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(18, 10))
    plt.imshow(image_rgb)
    plt.axis('off')
    plt.title('Annotations')
    plt.text(10, image_rgb.shape[0] + 100, f'Image: {image_name}', color='black', fontsize=11, ha='left')
    plt.show()
    return image

image_name = '11_spur_09.jpg'
visualize_annotations(image_name, images_dir, annot_df, is_subfolder=True);

"""**Dataset Preprocessing**"""

def resize_images(input_dir, output_dir, target_size=(640, 640)):

    #Resizes all .jpg images in the input directory (including subfolders)
    #to the target_size and saves them to the output directory.

    # Create the output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # Traverse through all subfolders in the input directory
    for root, _, files in os.walk(input_dir):
        for file in files:
            # Process only .jpg files
            if file.lower().endswith(('.jpg')):
                image_path = os.path.join(root, file)
                image = cv2.imread(image_path)

                # Resize image to target size
                resized_image = cv2.resize(image, target_size)

                # Construct full output path and save the resized image
                output_path = os.path.join(output_dir, file)
                cv2.imwrite(output_path, resized_image)

# Define directory for resized images and execute resizing function
resized_img_dir = os.path.join(dataset_dir, 'images_resized')
resize_images(images_dir, resized_img_dir)

def resize_annotations(annot_df, target_size=(640, 640)):

    # Resizes bounding box coordinates to correspond with images resized to target_size.

    all_data = []
    for index, row in annot_df.iterrows():
        # Compute scaling ratios based on original and target dimensions.
        width_ratio = target_size[0] / row['width']
        height_ratio = target_size[1] / row['height']

        # Calculate new bounding box coordinates.
        resized_xmin = int(row['xmin'] * width_ratio)
        resized_ymin = int(row['ymin'] * height_ratio)
        resized_xmax = int(row['xmax'] * width_ratio)
        resized_ymax = int(row['ymax'] * height_ratio)

        # Append the updated annotation data.
        all_data.append({
            'filename': row['filename'],
            'width': target_size[0],
            'height': target_size[1],
            'class': row['class'],
            'xmin': resized_xmin,
            'ymin': resized_ymin,
            'xmax': resized_xmax,
            'ymax': resized_ymax
        })

    return pd.DataFrame(all_data)

# Generate a new annotations DataFrame with resized bounding boxes and show a sample.
annot_df_resized = resize_annotations(annot_df)
print("Sample of resized annotations:")
print(annot_df_resized.head())

"""**Split Dataset**"""

# Create the main output directory for the split dataset
output_dir = os.path.join(dataset_dir, 'output')
os.makedirs(output_dir, exist_ok=True)

# Convert annotation DataFrame into YOLO labels
# YOLO format: <class_index> <x_center> <y_center> <width> <height>
def convert_to_yolo_labels(annotation_df, classes, target_size=(640, 640)):
    yolo_labels = []

    for _, annot in annotation_df.iterrows():
        filename = annot['filename']
        width, height = annot['width'], annot['height']
        class_name = annot['class']
        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']

        # Convert bounding box coordinates to YOLO format using normalized values.
        x_center = (xmin + xmax) / (2 * width)
        y_center = (ymin + ymax) / (2 * height)
        bbox_width = (xmax - xmin) / width
        bbox_height = (ymax - ymin) / height

        class_index = classes.index(class_name)

        # Determine the numerical label based on the class name.
        yolo_labels.append((filename, class_index, x_center, y_center, bbox_width, bbox_height))

    return yolo_labels

# Define the list of classes.
classes = ['missing_hole', 'mouse_bite', 'open_circuit',
           'short', 'spur', 'spurious_copper']
yolo_labels = convert_to_yolo_labels(annot_df_resized, classes)

def split_images_and_labels(images_dir, labels, output_dir, train_split=0.85, val_split=0.15):
    # os.makedirs(output_dir, exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)
    # os.makedirs(os.path.join(output_dir, 'images/test'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)
    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)
    # os.makedirs(os.path.join(output_dir, 'labels/test'), exist_ok=True)

    # Group labels by image filename
    image_labels = {}
    for label in labels:
        filename, class_index, x_center, y_center, bbox_width, bbox_height = label
        if filename not in image_labels:
            image_labels[filename] = []
        image_labels[filename].append(label)

    # Shuffle the list of image filenames to ensure random distribution
    image_filenames = list(image_labels.keys())
    random.shuffle(image_filenames)

    # Calculate the number of images for each split
    num_images = len(image_filenames)
    num_train = int(num_images * train_split)
    num_val = int(num_images * val_split)

    train_filenames = image_filenames[:num_train]
    val_filenames = image_filenames[num_train:num_train + num_val]
    test_filenames = image_filenames[num_train + num_val:]

    # Write out the labels and copy corresponding images for each split.
    for dataset, filenames in [('train', train_filenames), ('val', val_filenames), ('test', test_filenames)]:
        for filename in filenames:
            labels = image_labels[filename]
            with open(os.path.join(output_dir, f'labels/{dataset}/{os.path.splitext(filename)[0]}.txt'), 'a') as label_file:
                for label in labels:
                    _, class_index, x_center, y_center, bbox_width, bbox_height = label
                    label_file.write(f"{class_index} {x_center} {y_center} {bbox_width} {bbox_height}\n")
            # Copy images to corresponding folders
            shutil.copy(os.path.join(images_dir, filename), os.path.join(output_dir, f'images/{dataset}/{filename}'))

split_images_and_labels(resized_img_dir, yolo_labels, output_dir)

"""***K*-Fold Cross Validation**"""

dataset_path = Path(output_dir)
labels = sorted(dataset_path.rglob("*labels/train/*.txt")) # all data in 'labels'

cls_idx = list(range(len(classes)))
print(list(zip(classes, cls_idx)))

indx = [l.stem for l in labels] # uses base filename as ID (no extension)
labels_df = pd.DataFrame([], columns=cls_idx, index=indx)

for label in labels:
    lbl_counter = Counter()

    with open(label,'r') as lf:
        lines = lf.readlines()

    for l in lines:
        # classes for YOLO label uses integer at first position of each line
        lbl_counter[int(l.split(' ')[0])] += 1

    labels_df.loc[label.stem] = lbl_counter

labels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`
labels_df.head()

ksplit = 3
kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)   # setting random_state for repeatable results

kfolds = list(kf.split(labels_df))

folds = [f'split_{n}' for n in range(1, ksplit + 1)]
folds_df = pd.DataFrame(index=indx, columns=folds)

for idx, (train, val) in enumerate(kfolds, start=1):
    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'
    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'

fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)

for n, (train_indices, val_indices) in enumerate(kfolds, start=1):
    train_totals = labels_df.iloc[train_indices].sum()
    val_totals = labels_df.iloc[val_indices].sum()

    # To avoid division by zero, we add a small value (1E-7) to the denominator
    ratio = val_totals / (train_totals + 1E-7)
    fold_lbl_distrb.loc[f'split_{n}'] = ratio

fold_lbl_distrb

# Initialize a list to store image file paths
images = sorted(dataset_path.rglob("*images/train/*.jpg"))

# Create the necessary directories and dataset YAML files (unchanged)
save_path = Path(dataset_path / f'{ksplit}fold_crossval')
save_path.mkdir(parents=True, exist_ok=True)
ds_yamls = []

for split in folds_df.columns:
    # Create directories
    split_dir = save_path / split
    split_dir.mkdir(parents=True, exist_ok=True)
    (split_dir / 'train' / 'images').mkdir(parents=True, exist_ok=True)
    (split_dir / 'train' / 'labels').mkdir(parents=True, exist_ok=True)
    (split_dir / 'val' / 'images').mkdir(parents=True, exist_ok=True)
    (split_dir / 'val' / 'labels').mkdir(parents=True, exist_ok=True)

    # Create dataset YAML files
    dataset_yaml = split_dir / f'{split}_dataset.yaml'
    ds_yamls.append(dataset_yaml)

    with open(dataset_yaml, 'w') as ds_y:
        yaml.safe_dump({
            'path': split_dir.as_posix(),
            'train': 'train',
            'val': 'val',
            'names': classes
        }, ds_y)

for image, label in zip(images, labels):
    for split, k_split in folds_df.loc[image.stem].items():
        # Destination directory
        img_to_path = save_path / split / k_split / 'images'
        lbl_to_path = save_path / split / k_split / 'labels'

        # Copy image and label files to new directory
        shutil.copy(image, img_to_path / image.name)
        shutil.copy(label, lbl_to_path / label.name)

folds_df.to_csv(save_path / "kfold_datasplit.csv")
fold_lbl_distrb.to_csv(save_path / "kfold_label_distribution.csv")

project = '/content/drive/MyDrive/PCB_defect_detection/pcb'

"""Model Training"""

model = YOLO('yolov8s.pt')
results = {}

# Additional arguments here
batch = 15
project = 'pcb'
#project = '/content/drive/MyDrive/PCB_defect_detection/pcb'
epochs = 150
imgsz=640
save_period=1
verbose=True
mixup = 0.3 # Blends two images and their labels, creating a new image

#AdamW optimizer used
for k in range(ksplit):
    dataset_yaml = ds_yamls[k]
    model.train(data=dataset_yaml,
                epochs=epochs,
                batch=batch,
                lr0=0.001,
                lrf=0.0001,
                imgsz=imgsz,
                save_period=save_period,
                verbose=verbose,
                project=project,
                mixup=mixup)
    results[k] = model.metrics  # save output metrics

"""Model"""

model = YOLO('yolov8s.pt')

batch = 15
#project = '/content/drive/MyDrive/PCB_defect_detection/pcb'
project = 'pcb'
epochs = 150
imgsz=640
save_period=1
verbose=True
mixup = 0.3 # Blends two images and their labels, creating a composite image

all_data_yaml = f"""
path: {output_dir}
train: images/train
val: images/val

names:
    0: missing_hole
    1: mouse_bite
    2: open_circuit
    3: short
    4: spur
    5: spurious_copper
"""

data_path = os.path.join(root_dir, 'data.yaml')

with open(data_path, 'w') as f:
    f.write(all_data_yaml)

#AdamW optimizer used
result = model.train(data=data_path,
                     epochs=epochs,
                     batch=batch,
                     lr0=0.001,
                     lrf=0.0001,
                     imgsz=imgsz,
                     save_period=save_period,
                     verbose=verbose,
                     project=project,
                     mixup=mixup)

src_dir = '/content/pcb'
dst_dir = '/content/drive/MyDrive/PCB_defect_detection/pcb_results'

# Copy best training results to destination (after completing model training)
shutil.copytree(src_dir, dst_dir)

results_dir = 'pcb/train3'
dest_results_dir = os.path.join(root_dir, 'results2')

shutil.copytree(results_dir, dest_results_dir)

results_df = pd.read_csv(os.path.join(dest_results_dir, 'results.csv'))
results_df.columns = results_df.columns.str.strip()
results_df = results_df.apply(pd.to_numeric, errors='coerce').dropna()
results_df.head()

import matplotlib.pyplot as plt

"""Predict on Test Data"""

best_model_path = os.path.join(dest_results_dir, 'weights/best.pt')
model = YOLO(best_model_path)

test_data_dir = os.path.join(output_dir, 'images/val')
metrics = model(source=test_data_dir, imgsz=640, conf=0.25, save=True, save_txt=True, save_conf=True)

# Define source and destination directories
src_dir2 = '/content/runs/detect/predict'
dst_dir2 = '/content/drive/MyDrive/PCB_defect_detection/pcb_results/predict'

shutil.copytree(src_dir2, dst_dir2)

predict_dir = 'runs/detect/predict'
dest_predict_dir = os.path.join(root_dir, 'results/predict')

#shutil.copytree(predict_dir, dest_predict_dir)

def yolo_to_original_annot(image_name, yolo_labels, annot_df, classes):
    #Convert YOLO-formatted labels to original image coordinates.
    original_annot = []

    # Retrieve original dimensions for the given image from the annotations DataFrame.
    original_size = annot_df.loc[annot_df['filename'] == image_name, ['width', 'height']].iloc[0]
    original_width, original_height = original_size['width'], original_size['height']

    for yolo_label in yolo_labels:
        # Unpack label components.
        class_index, x_center, y_center, bbox_width, bbox_height, confidence = yolo_label

        # Scale normalized coordinates back to the original image size.
        original_x_center = x_center * original_width
        original_y_center = y_center * original_height
        original_bbox_width = bbox_width * original_width
        original_bbox_height = bbox_height * original_height

        # Calculate the top-left and bottom-right coordinates of the bounding box.
        original_x_min = original_x_center - original_bbox_width / 2
        original_y_min = original_y_center - original_bbox_height / 2
        original_x_max = original_x_center + original_bbox_width / 2
        original_y_max = original_y_center + original_bbox_height / 2

        # Append the converted annotation as a dictionary.
        original_annot.append({
            'filename': image_name,
            'width': int(original_width),
            'height': int(original_height),
            'class': classes[int(class_index)],
            'xmin': int(original_x_min),
            'ymin': int(original_y_min),
            'xmax': int(original_x_max),
            'ymax': int(original_y_max),
            'confidence': confidence
        })

    return pd.DataFrame(original_annot)

def read_yolo_labels_from_file(file_path):
    labels = []
    with open(file_path, 'r') as file:
        for line in file:
            values = line.strip().split()
            values = [float(value) for value in values]
            labels.append(values)
    return labels

file_path = os.path.join(dest_predict_dir, 'labels/04_short_12.txt')
yolo_labels = read_yolo_labels_from_file(file_path)
yolo_labels

pred_annot_df = yolo_to_original_annot('04_short_12.jpg', yolo_labels, annot_df, classes)
pred_annot_df.head()

visualize_annotations('04_short_12.jpg', images_dir, pred_annot_df, is_subfolder=True);

visualize_annotations('04_short_12.jpg', images_dir, annot_df, is_subfolder=True);

model.export()

custom_img_dir = os.path.join(root_dir, 'custom_images')
resized_custom_img_dir = os.path.join(custom_img_dir, 'resized')
resize_images(custom_img_dir, resized_custom_img_dir)

model = YOLO(best_model_path)

image_path = os.path.join(resized_custom_img_dir, '04_short_11.jpg')
result_custom = model(image_path, imgsz=640, conf=0.3, save=True, save_txt=True, save_conf=True)